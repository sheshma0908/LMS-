{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93fe21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "-3\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "a=19\n",
    "b=22\n",
    "c=18\n",
    "print(a+b+c)\n",
    "print(a-b)\n",
    "print(a*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941ac171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number89\n",
      "89\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "a=int(input(\"Enter a number\"))\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23added",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number18\n",
      "18\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "a=(input(\"Enter a number\"))\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b1ea8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of this person is Meghna,and age is 19\n"
     ]
    }
   ],
   "source": [
    "name=\"Meghna\"\n",
    "age=19\n",
    "print(f\"Name of this person is {name},and age is {age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d070163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Name:Vishwa\n",
      "Enter your age:19\n",
      "Name of the person is Vishwa,and age is 19\n"
     ]
    }
   ],
   "source": [
    "name=input(\"Enter your Name:\")\n",
    "age=int(input(\"Enter your age:\"))\n",
    "print(f\"Name of the person is {name},and age is {age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29859d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your otp:1020\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "otp=int(input(\"Enter your otp:\"))\n",
    "if otp==1819:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454624ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your otp:1819\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "otp=int(input(\"Enter your otp:\"))\n",
    "if otp==1819:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14d25254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a=24\n",
    "b=55\n",
    "c=98\n",
    "d=98\n",
    "print(a>b)\n",
    "print(a>=b)\n",
    "print(b<c)\n",
    "print(c==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8696c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a=24\n",
    "b=55\n",
    "c=98\n",
    "print(a>b and a>c)\n",
    "print(a<b and a<c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efec466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a=24\n",
    "b=55\n",
    "c=98\n",
    "print(a>b or a>c)\n",
    "print(a<b or a<c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a3c4461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a=24\n",
    "b=55\n",
    "c=98\n",
    "print(a>b and a>c or a<c)\n",
    "print(a<b and a<c or a<=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b84d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n"
     ]
    }
   ],
   "source": [
    "a=\"machine learning\"\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb141f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "a=\"machine learning\"\n",
    "print(a[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888ff2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine\n"
     ]
    }
   ],
   "source": [
    "a=\"machine learning\"\n",
    "print(a[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825e4926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce6c586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:7:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60986c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mcie'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:7:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a888f7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:7:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "873b190a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d741364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ael enihc'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[10:1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58e5ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihi\n",
      "hihello\n"
     ]
    }
   ],
   "source": [
    "a='hi'\n",
    "b='hello'\n",
    "print(a*2)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9505a516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"HELLO\"\n",
    "a.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07875645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HUMAN'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=\"human\"\n",
    "b.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3eedec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'technology',\n",
       " 'that',\n",
       " 'gives',\n",
       " 'computers',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'interpret,',\n",
       " 'manipulate,',\n",
       " 'and',\n",
       " 'comprehend',\n",
       " 'human',\n",
       " 'language.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.\"\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "561eb446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEChnOlOgy'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"tecHNoLoGY\"\n",
    "a.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "818dfeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t$e$c$H$N$o$L$o$G$Y'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"$\".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ec95302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.isspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68314e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "007\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern=r'\\w+'\n",
    "text=\"the 008 jersy 007 number of dhoni\"\n",
    "match=re.search(pattern,text)\n",
    "print(match.group())\n",
    "pattern=r'\\d+'\n",
    "text=\"007 is the 008 jersy number of dhoni\"\n",
    "match=re.search(pattern,text)\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090b6f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['008', '007']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern=r'\\d+'\n",
    "text=\"the 008 jersy 007 number of dhoni\"\n",
    "match=re.findall(pattern,text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54000560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ti like you so much hari'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern=r\"\\d+\"\n",
    "text=\"ti like you so much 007\"\n",
    "new=re.sub(pattern, \"hari\",text)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab761fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', text)\n",
    "    text_no_numbers = re.sub(r'\\d+', '', text)\n",
    "    hashtags = re.findall(r'#\\w+', text)\n",
    "    text_normalized = re.sub(r'\\s+', ' ', text_no_numbers).strip()\n",
    "    text_no_html = re.sub\n",
    "    return {\n",
    "        \"emails\" : emails,\n",
    "        \"hashtags\" : hashtags,\n",
    "        \"clean_text\" : text_no_html\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d9a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['info@example.com', 'support123@company.org']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\"\n",
    "Hello world! Contact us at info@example.com or support123@company.org. Follow us on social media: #AI #MachineLearning.\n",
    "Visit <a href=\"http://example.com\">our website</a> for more details. This is a test with number 1234.\n",
    "\"\"\"\n",
    "emails=re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',text)\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a891a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#AI', '#MachineLearning']\n"
     ]
    }
   ],
   "source": [
    "hashtags=re.findall(r'#\\w+',text)\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4d6168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello world! Contact us at info@example.com or support@company.org. Follow us on social media: #AI #MachineLearning.\n",
      "Visit <a href=\"http://example.com\">our website</a> for more details. This is a test with number .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_no_numbers=re.sub(r'\\d+','',text)\n",
    "print(text_no_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15639a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello world! Contact us at info@example.com or support@company.org. Follow us on social media: #AI #MachineLearning.\n",
      "Visit our website for more details. This is a test with number .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_text=re.sub(r\"<.*?>\",'',text_no_numbers)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9157331a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 're' has no attribute 's'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Test case\u001b[39;00m\n\u001b[0;32m     26\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124mHello world! Contact us at info@example.com or support123@company.org. Follow us on social media: #AI #MachineLearning.\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124mVisit <a href=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://example.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>our website</a> for more details. This is a test with number 1234.\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclean_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmails Found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memails\u001b[39m\u001b[38;5;124m'\u001b[39m])          \n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHashtags Found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashtags\u001b[39m\u001b[38;5;124m'\u001b[39m])    \n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mclean_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     15\u001b[0m text_normalized \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, text_no_numbers)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 5: Remove any HTML tags\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m text_no_html \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memails\u001b[39m\u001b[38;5;124m\"\u001b[39m : emails,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashtags\u001b[39m\u001b[38;5;124m\"\u001b[39m : hashtags,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m\"\u001b[39m : text_no_html\n\u001b[0;32m     24\u001b[0m }\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 're' has no attribute 's'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Step 1: Extract all email addresses\n",
    "    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', text)\n",
    "\n",
    "\n",
    "\n",
    "    # Step 2: Extract all hashtags\n",
    "    hashtags = re.findall(r'#\\w+', text)\n",
    "     # Step 3: Remove all numbers\n",
    "    text_no_numbers = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Step 4: Normalize whitespace (remove extra spaces)\n",
    "    text_normalized = re.sub(r'\\s+', ' ', text_no_numbers).strip()\n",
    "\n",
    "    # Step 5: Remove any HTML tags\n",
    "    text_no_html = re.s\n",
    "    \n",
    "    return {\n",
    "        \"emails\" : emails,\n",
    "        \"hashtags\" : hashtags,\n",
    "        \"clean_text\" : text_no_html\n",
    "    }\n",
    "# Test case\n",
    "text = \"\"\"\n",
    "Hello world! Contact us at info@example.com or support123@company.org. Follow us on social media: #AI #MachineLearning.\n",
    "Visit <a href=\"http://example.com\">our website</a> for more details. This is a test with number 1234.\n",
    "\"\"\"\n",
    "result = clean_text(text)\n",
    "print(\"Emails Found:\", result['emails'])          \n",
    "print(\"Hashtags Found:\", result['hashtags'])    \n",
    "print(\"Cleaned Text:\", result['clean_text'])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b28ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿id keyword       location  \\\n",
       "0      0  ablaze            NaN   \n",
       "1      1  ablaze            NaN   \n",
       "2      2  ablaze  New York City   \n",
       "\n",
       "                                                text  target  \n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2  Arsonist sets cars ablaze at dealership https:...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('tweets.csv', encoding = 'ISO-8859-1')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ff58a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "were          2\n",
       "houses        2\n",
       "and           2\n",
       "Communal      1\n",
       "violence      1\n",
       "in            1\n",
       "Bhainsa,      1\n",
       "Telangana.    1\n",
       "\"Stones       1\n",
       "pelted        1\n",
       "on            1\n",
       "Muslims'      1\n",
       "some          1\n",
       "vehicles      1\n",
       "set           1\n",
       "ablazeâ¦     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_freq(text):\n",
    "    word_list=[]\n",
    "    for tw_words in text.split():\n",
    "        word_list.extend(tw_words)\n",
    "        word_freq=pd.Series(word_list).value_counts()\n",
    "        word_freq[:10]\n",
    "        return word_freq\n",
    "word_freq = gen_freq(dataset.text.str)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b169ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "were          2\n",
       "houses        2\n",
       "and           2\n",
       "Communal      1\n",
       "violence      1\n",
       "in            1\n",
       "Bhainsa,      1\n",
       "Telangana.    1\n",
       "\"Stones       1\n",
       "pelted        1\n",
       "on            1\n",
       "Muslims'      1\n",
       "some          1\n",
       "vehicles      1\n",
       "set           1\n",
       "ablazeâ¦     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = gen_freq(dataset.text.str)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5f0a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.4-cp39-cp39-win_amd64.whl (300 kB)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wordcloud_cli.exe is installed in 'C:\\Users\\kalle\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf89364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'its', 'some', 'with', \"couldn't\", 'again', 'up', 'down', 'ought', \"i'd\", 'your', 'would', \"i'll\", 'me', 'they', 'hence', \"shouldn't\", \"she'll\", \"i'm\", 'theirs', 'each', 'not', 'other', 'more', \"why's\", \"we've\", 'was', 'on', 'in', 'is', 'into', 'these', 'an', 'as', 'all', 'before', \"aren't\", 'a', \"he'll\", \"haven't\", 'at', 'herself', 'www', 'myself', 'to', 'do', 'did', 'when', 'it', 'ourselves', 'else', 'that', 'ever', 'but', 'nor', 'she', \"isn't\", 'out', \"mustn't\", 'this', 'itself', 'such', 'himself', 'yours', \"we'll\", \"they're\", \"you've\", 'by', \"i've\", 'just', 'like', 'about', 'her', \"we'd\", 'our', 'no', 'while', 'you', \"you'd\", 'once', 'yourselves', 'hers', 'having', 'since', 'otherwise', \"don't\", 'his', 'am', 'does', 'had', \"we're\", \"can't\", 'we', \"hadn't\", 'ours', 'themselves', 'too', 'been', \"let's\", 'get', 'few', 'have', \"they'll\", 'those', 'why', \"it's\", 'or', \"won't\", 'also', 'and', \"weren't\", 'could', \"wasn't\", \"hasn't\", 'k', 'being', 'be', 'them', \"she'd\", 'http', 'through', 'r', 'yourself', 'he', 'over', \"who's\", 'here', \"he'd\", 'can', 'what', \"when's\", 'cannot', 'above', 'who', 'during', \"they'd\", 'are', \"where's\", 'com', 'were', 'under', \"you're\", 'where', 'then', 'both', 'him', \"how's\", \"shan't\", 'my', 'so', 'against', 'because', 'if', 'should', 'the', 'how', \"he's\", 'doing', 'than', \"what's\", 'only', 'any', 'after', \"you'll\", 'which', \"here's\", 'therefore', \"wouldn't\", 'whom', 'of', 'same', 'has', 'between', 'their', \"she's\", 'from', 'however', 'further', 'off', \"that's\", 'own', 'most', \"didn't\", 'there', \"there's\", 'shall', \"they've\", 'for', \"doesn't\", 'until', 'below', 'very', 'i'}\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "635dfbfd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m word_freq \u001b[38;5;241m=\u001b[39m gen_freq(text\u001b[38;5;241m.\u001b[39mstr)\n\u001b[0;32m      3\u001b[0m word_freq \u001b[38;5;241m=\u001b[39m word_freq\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39mSTOPWORDS, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mclean_text\u001b[49m(x))\n\u001b[0;32m      2\u001b[0m word_freq \u001b[38;5;241m=\u001b[39m gen_freq(text\u001b[38;5;241m.\u001b[39mstr)\n\u001b[0;32m      3\u001b[0m word_freq \u001b[38;5;241m=\u001b[39m word_freq\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39mSTOPWORDS, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_text' is not defined"
     ]
    }
   ],
   "source": [
    "text = dataset.text.apply(lambda x: clean_text(x))\n",
    "word_freq = gen_freq(text.str)\n",
    "word_freq = word_freq.drop(labels=STOPWORDS, errors='ignore')\n",
    "wc = WordCloud(width=400, height=330, max_words=200,background_color='white').generate_from_frequencies(word_freq)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dab85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
