{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNKrmmpxBAiytI6nqXmMkZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheshma0908/LMS-/blob/main/13_03_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-imw4zIWSs4"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('.',' *')\n",
        "  return Markdown(textwrap.indent(text, '>',predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "l5QoSRUBX2Lf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "img = PIL.Image.open('/var/image1.jpg')\n",
        "img\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response =model.generate_content([\"Write a short, engaging blog post basedon this picture.It should include a description of themeal in the photo and talk about my journey meal prepping.\", img],\n",
        "stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "8RW1VrtMZYgH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "6rlujW_vbVaQ",
        "outputId": "9e9d4eee-3032-4b68-fed1-e4be2d4ffd9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">## My Meal Prep Journey: From Chaos to Colorful Containers!\n>\n>Look at these beauties!  These aren't just any takeout containers; these are my meticulously crafted, healthy lunch heroes for the week *  Each one is packed with fluffy white rice, tender slices of teriyaki chicken, vibrant roasted carrots and peppers, and a generous helping of broccoli *  It’s a balanced, delicious, and satisfying meal that makes my workdays so much easier (and healthier!) *\n>\n>My journey into meal prepping hasn't always been this picture-perfect *  I used to be a queen of last-minute lunch decisions, usually resulting in something questionable from the vending machine or a sad desk salad * I knew I needed to change but the thought of spending hours prepping food on the weekend felt daunting *\n>\n>But I’m happy to report I've finally cracked the code! It all started with small steps:  I began by prepping just one or two components at a time – chopping veggies on Sunday evening, or cooking a large batch of rice * Gradually, I built up to doing the full meal prep, finding that the time commitment was actually less than I expected, and the satisfaction was immense * \n>\n>Now, meal prepping isn't a chore; it's a form of self-care *  The peace of mind knowing I have delicious, healthy meals ready to go makes a huge difference in my energy levels and productivity *  Plus, it saves me money and cuts down on impulsive unhealthy food choices *  So, if you're thinking about starting your own meal prep journey, just take that first small step * You might just surprise yourself!\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\", img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "nHc-zYDRcDud",
        "outputId": "4cf3a579-2299-46ff-b276-2fe30e0ac277"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are a few caption options for the image:\n",
            "\n",
            "**Option 1 (Simple & Descriptive):**\n",
            "\n",
            "> Healthy and delicious meal prep!  Chicken and broccoli with rice.\n",
            "\n",
            "**Option 2 (Slightly More Engaging):**\n",
            "\n",
            "> Lunch goals! These chicken and veggie bowls are packed with flavor and ready to go.  #mealprep #healthyfood #lunchideas\n",
            "\n",
            "**Option 3 (Focus on Convenience):**\n",
            "\n",
            "> Easy weeknight dinners start with smart meal prep.  Grab and go healthy meals made easy. #mealprepsunday #healthylifestyle #convenientmeals\n",
            "\n",
            "\n",
            "**Option 4 (More Detailed):**\n",
            "\n",
            "> Two delicious servings of teriyaki chicken and broccoli over rice, prepped and ready for a quick and healthy meal! #teriyaki #mealprepping #healthyfood #easyrecipes\n",
            "\n",
            "\n",
            "Choose the caption that best suits your intended audience and platform.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/image 2.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "hV3vuA4VeDVI",
        "outputId": "33e53f6e-c439-4de7-f534-1cb27794a04f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Eye-level view of a long, tree-lined pathway. \n",
            "\n",
            "\n",
            "Here's a breakdown of the scene:\n",
            "\n",
            "* **Trees:** The pathway is flanked on both sides by tall, slender trees. The trees on the right side are predominantly a vibrant, reddish-orange autumnal color, while the trees on the left are mostly a darker, muted green, creating a striking contrast. Some trees show a mix of both colors. The trees appear to be of the same species, possibly metasequoia (dawn redwood). They are evenly spaced, forming a tunnel-like effect over the path. In the background, beyond the main line of trees, there are more trees that appear smaller and less colorful, suggesting a slight haze or distance.\n",
            "\n",
            "* **Path:** The pathway itself is a wide, dirt or gravel path, light brown in color. It stretches into the distance, vanishing point toward the center of the image. The path appears relatively flat and even.\n",
            "\n",
            "* **Person:** A small, distant figure of a person is visible in the middle of the path.  The person appears to be standing and is too small to discern any detail. The person seems to be holding something like a camera or similar device, possibly taking a photograph.\n",
            "\n",
            "* **Atmosphere:** The overall atmosphere is serene and peaceful. A slight haziness or fog is visible in the background, softening the details of the distant trees and adding to the tranquil mood. The lighting suggests it might be an overcast day.\n",
            "\n",
            "* **Ground Cover:** At the base of the trees, there's a low-lying ground cover of green plants, neatly bordering the path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "BXewD-V-h1RI",
        "outputId": "879accd8-87a0-4ab0-fd69-5ea11db84e7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image evokes feelings of serenity, peacefulness, and perhaps a touch of loneliness or contemplation.  The symmetry of the trees, the muted colors, and the solitary figure in the distance all contribute to this mood.  The autumnal colors might also suggest a sense of melancholy or nostalgia for some viewers, while others might find them beautiful and vibrant.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/dark.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Ynp6BdsBgovc",
        "outputId": "758445de-b07e-43c0-90ee-333588a4a4bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "The photograph is a monochrome, high-contrast image depicting a solitary streetlight illuminating a curving roadway at night. \n",
            "\n",
            "\n",
            "Here's a breakdown of the details:\n",
            "\n",
            "* **Lighting:** The scene is overwhelmingly dark, with the exception of the area directly lit by the streetlamp. The light creates a strong chiaroscuro effect, with deep blacks contrasting sharply against the bright white of the lamp and the pavement it illuminates. The light source itself is a bright point of light at the top of the lamppost, indicating a powerful bulb.\n",
            "\n",
            "* **Streetlight:** A tall, slender streetlight stands prominently in the middle-right of the frame. Its design is simple and unadorned, with a vertical pole supporting a single light fixture.\n",
            "\n",
            "* **Roadway:** A dark asphalt roadway curves gently to the left, receding into the background.  The curve leads away from the viewer and towards a mostly obscured area. The curve is highlighted where the light from the street lamp reaches.\n",
            "\n",
            "* **Vegetation:** Dark, shadowy foliage is visible to the right of the streetlamp, creating a strong contrast against the bright light. The vegetation appears to be low-lying shrubs and possibly the lower branches of a tree, all of which are rendered in shades of gray.\n",
            "\n",
            "* **Sidewalk:** A concrete sidewalk is partially visible, extending from the base of the streetlight, and following the curve of the road. \n",
            "\n",
            "\n",
            "The overall mood is one of quiet solitude and mystery. The stark contrast between light and dark, and the empty, curving road, evoke a sense of isolation and perhaps even unease. The image is very clean in terms of composition, focusing attention on the streetlamp as the central element of the scene.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "aPIcaAc-huum",
        "outputId": "ef88c50d-95e2-42aa-8028-56f03a3f1b03"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image evokes feelings of loneliness, isolation, and perhaps a touch of mystery or unease. The single, brightly lit lamppost in the vast darkness emphasizes the emptiness and creates a sense of vulnerability.  The overall mood is somber and quiet.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/cute.png'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "dj2ybfcrhAuO",
        "outputId": "bd348d53-e841-4a38-bde6-cf4d88f7a24d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "The image is a simple, minimalist cartoon featuring two adorable chibi-style characters against a solid light pink background. \n",
            "\n",
            "\n",
            "The main character is a brown bear cub, depicted in a sailor-style, light blue dress with a small bow at the neck. It has large, expressive eyes, rosy cheeks, and a small, happy open mouth showing a tongue. The bear is standing upright, with its arms raised slightly.\n",
            "\n",
            "Sitting on the bear's back is a smaller, white character with black ears, resembling a panda or a bunny hybrid. This character is wearing a light pink dress and has similar large, friendly eyes and rosy cheeks. A tiny, simplified bunny-like head is depicted as an accessory on its head.\n",
            "\n",
            "\n",
            "Both characters are drawn in a soft, rounded style characteristic of kawaii aesthetics, focusing on cuteness and simplicity. The linework is clean and consistent. The overall color palette is pastel, with muted browns, light blues, and pinks, contributing to the gentle and heartwarming mood of the illustration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "JNz4Wjs3hT0L",
        "outputId": "5600c93c-935e-40b1-f47b-44c4a6585370"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image evokes feelings of happiness, joy, and affection.  The characters' expressions are sweet and playful, suggesting a lighthearted and loving interaction. The overall style is cute and cuddly, contributing to these positive emotions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/logo1.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "eSbDzC3XiltO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "db3cc1d1-ab32-4f50-fbd3-b419222b1b47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for Amazon. \n",
            "\n",
            "\n",
            "The image shows the word \"amazon\" in a bold, black, sans-serif font. Underneath the word is a stylized orange smile, which is a key component of the Amazon logo. The background is transparent, allowing the logo to be placed on various backgrounds without visual interference.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "OCzIQfb5OP03",
        "outputId": "31b6eba6-904f-4742-f1fe-f1c8394c2604"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Amazon logo itself does not evoke emotions.  Logos are designed to be recognizable and represent a brand, not to directly express feelings.  Any emotional response to the Amazon logo is entirely based on the viewer's personal experiences and associations with the company and its products/services.  Someone might feel excitement (about a purchase), frustration (with customer service), or indifference, depending on their individual history with Amazon.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/product.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "T592fMT7OS7-",
        "outputId": "cf3e0ff7-88f0-405e-d159-033a8041de58"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "High-angle, close-up view of a pair of black over-ear headphones resting on a bright yellow background. \n",
            "\n",
            "\n",
            "The headphones are sleek and modern in design. The earcups are smooth and appear to be made of a soft, possibly leather-like material. The headband is also black and has a slightly textured surface. The headphones are positioned so that the headband curves gently upwards, and the earcups are slightly angled towards the bottom right of the frame. \n",
            "\n",
            "\n",
            "The yellow background is uniform and provides a stark contrast to the dark color of the headphones, making them stand out prominently. The lighting is even, minimizing shadows and highlighting the shape and texture of the headphones.  There is a small, barely visible detail on the right earcup that could be a small control button or indicator light.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "UsrLhhcOObv2",
        "outputId": "6e6cf68c-e32c-4d3e-8e86-44ee2b924538"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the image provided, focusing on the style and features:\n",
            "\n",
            "**Focusing on Over-Ear, Closed-Back Design:**\n",
            "\n",
            "* **Sony WH-CH710N:** These offer noise cancellation at a more affordable price point than some premium models, still maintaining good sound quality and a comfortable fit.\n",
            "* **Audio-Technica ATH-M50x:** Known for their studio-quality sound, these are a popular choice among musicians and audiophiles.  They are closed-back, which helps block out external noise.\n",
            "* **AKG K361:**  Another closed-back option offering great sound quality for the price, known for their comfort and foldable design.\n",
            "* **Sennheiser HD 280 PRO:** These are focused on monitoring and studio use, offering exceptional sound isolation and durable build quality.  Slightly more rugged than the others listed.\n",
            "\n",
            "\n",
            "**Things to Consider When Choosing a Similar Product:**\n",
            "\n",
            "* **Noise Cancellation:** Does noise cancellation matter to you?  The original image doesn't clearly indicate this feature.\n",
            "* **Sound Quality:**  Do you prioritize bass, treble, or a balanced sound?\n",
            "* **Comfort:**  How long do you plan to wear the headphones? Consider earpad size and material.\n",
            "* **Budget:** Prices vary drastically among headphone models.\n",
            "* **Features:**  Bluetooth connectivity, wired connection, microphone, etc.\n",
            "\n",
            "\n",
            "When searching for similar products online, use keywords like \"over-ear headphones,\" \"closed-back headphones,\" \"black headphones,\" and combine them with brand names from the list above.  You can also specify features like \"noise cancelling\" if desired.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/invoice.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ZrU7399xPkG3",
        "outputId": "4b72c49f-e320-470b-c58e-e1376d5d76f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "The image is a formal invoice template. \n",
            "\n",
            "\n",
            "**Visual Elements:**\n",
            "\n",
            "* **Header:** The top features a purple and gold color scheme. A stylized logo (ω inside a circle) is present with the word \"LOGO\" and the placeholder text \"YOURTAGLINE\" below it. The word \"INVOICE\" is prominently displayed in bold, black text.\n",
            "\n",
            "* **Invoice Information:** The invoice number, date (August 13, 2021), and billing information (\"INVOICE TO: LOREM IPSUM,\" with additional placeholder address text) are clearly stated.\n",
            "\n",
            "* **Itemized List:** A table details the items, their price ($10.00 each), quantity (1 each), and total cost for each line item. There are five identical line items listed, all reading \"LOREM IPSUM DOLOR SIT AMET.\"\n",
            "\n",
            "* **Totals:** Subtotal, tax (10%), and grand total are calculated and displayed. The grand total is also $100.00, indicating a discrepancy, as the tax is not added.\n",
            "\n",
            "* **Payment Information:** A section provides space for account number, account name, and bank details; however, these are left as placeholders.\n",
            "\n",
            "* **Terms and Conditions:** A section for terms and conditions includes placeholder Latin text (\"Lorem ipsum...\").\n",
            "\n",
            "* **Footer:** The footer contains a \"Thank you for your business\" message and a space for an \"Authorized Sign.\" The footer also continues the purple and gold color scheme.\n",
            "\n",
            "\n",
            "**Overall Impression:**\n",
            "\n",
            "The invoice appears professional and clean. The color scheme is relatively modern, and the layout is easy to read.  The use of placeholder text indicates that this is a template meant to be customized. The discrepancy between the subtotal and grand total is likely an error in the template design.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "rSomqJHVSi1x",
        "outputId": "e1722aca-30b9-4d5a-89e3-6be8a29bdca9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** No discounts are applied.  The Grand Total is equal to the Sub Total plus tax.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/bicycle.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "RLIHCE7PSmA2",
        "outputId": "dc9e18d0-227a-4101-d7a6-6c46821df1e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Eye-level view of two men riding bicycles on a wet street. \n",
            "\n",
            "\n",
            "Here's a breakdown of the scene:\n",
            "\n",
            "* **The Men:** Two men are the focal point, both appearing to be of South Asian descent. The man on the left is wearing a bright blue t-shirt and camouflage shorts, while the man on the right wears a gray long-sleeved shirt, blue jeans, and a red baseball cap. They appear to be casually riding, not racing.\n",
            "\n",
            "* **The Bicycles:** The man on the left is riding a black and yellow bicycle, while the man on the right is on a white bicycle with the brand \"BTWIN\" visible on the frame. Both appear to be hybrid-style bicycles suitable for city riding.\n",
            "\n",
            "* **The Setting:** The scene is set in front of a building with a pale pink roller shutter door, a window with bars, and some visible interior space with chairs. A man can be seen sitting inside the building in the background. The street is wet, suggesting recent rain. Some vegetation is visible along the edge of the street. A motorcycle is parked to the left, slightly in the background.\n",
            "\n",
            "* **Overall Atmosphere:** The overall mood is calm and casual. It appears to be a daytime scene, likely in an urban or suburban area. The slightly wet street and the casual attire of the cyclists suggest an informal, possibly leisurely, ride.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/var/items.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "EHVhCQT7Twur",
        "outputId": "ebe14e25-2107-4c6a-b9f0-31f9ec60f813"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "The image is a colorful chart designed to teach the difference between countable and uncountable nouns in English. \n",
            "\n",
            "\n",
            "**Layout:** The chart is divided into two main sections: \"Countables\" on the left and \"Uncountables\" on the right, each with a light yellow and light blue background, respectively. A circular logo with the text \"LessonsForEnglish.Com\" sits between the sections.  Each section displays various food items in a grid format with their names written underneath.\n",
            "\n",
            "**Countables:** This section shows images of: eggs, a banana, olives, french fries, a hamburger, a hot dog, an apple, carrots, tomatoes, and a watermelon. These are all items that can be counted individually.\n",
            "\n",
            "**Uncountables:** This section presents images of: milk, flour, salt, sugar, jam, meat, rice, honey, tea, and cheese. These items are typically measured as quantities or masses rather than counted individually.\n",
            "\n",
            "**Visual Style:** The images of the food items are bright, cartoonish drawings, making them easily identifiable and visually appealing, especially for learners. The text is clear and easy to read, with a bold font used for the category titles (\"Countables\" and \"Uncountables\").\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"/var/items.jpg\")\n",
        "response = model.generate_content([\"List all objects in this image and count how many of each are present.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "9n0t5hr3UCwI",
        "outputId": "2098b7c4-7bc6-4470-c035-ff979b8e3087"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a count of the objects in the image:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olive: 2\n",
            "* Fries: 1 (serving)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (container)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (container)\n",
            "* Sugar: 1 (container)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (slices)\n",
            "* Rice: 1 (bowl)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBzpyVoIUaey",
        "outputId": "c94898cf-a5f7-4fb9-834f-c2afecb27330"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "def get_youtube_transcript(video_url):\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]  # Extract video ID\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "    return full_text\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "print(\"Transcript:\\n\", video_transcript[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjf6agA9Ul7p",
        "outputId": "a2ff8e75-4434-415c-8106-3de84636c91e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "0R5ehShRVmpR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "summary = summarize_video(video_transcript)\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "kYtTVETOWPSo",
        "outputId": "8c8fe077-b115-4f55-9797-7dd6e526d8f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " This YouTube video provides an introduction to machine learning.  It covers the definition of machine learning as learning from data,  highlighting its subfield within artificial intelligence.  The presenter explains that machine learning uses algorithms to build models from training data (past experiences) to predict future outcomes.  Several applications are discussed, including speech recognition, web search, recommendation systems, computer vision, information retrieval, and fraud detection.\n",
            "\n",
            "The video categorizes machine learning into three types: supervised (labeled data, used for classification and regression), unsupervised (unlabeled data, used for clustering and dimensionality reduction), and reinforcement learning (agent learns through trial and error and rewards/penalties).  Key concepts like data preprocessing (cleaning, scaling, encoding), algorithm selection (e.g., decision trees, random forests), model building, and evaluation are explained. The presenter emphasizes the importance of building multiple models and comparing their performance for reliable results.  Finally, the video promises future lessons focusing on hands-on case studies and practical implementation of various algorithms.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "insights = extract_video_insights(video_transcript)\n",
        "print(\"Key Insights:\\n\", insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "SVlWAOwFWULs",
        "outputId": "c60c22f7-3cf1-4f99-d18b-94fb563e7c5d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " This YouTube video provides an introduction to machine learning. Here are the key takeaways and insights:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "* **Definition:** Machine learning is essentially learning from data.  It's a subfield of artificial intelligence that allows computers to learn from data without explicit programming.  This learning process improves the computer's performance on a specific task over time.\n",
            "* **Core Concept:**  The process involves using past data (training data) to build a model that can predict future outcomes or events.  The model is created by applying a machine learning algorithm to the training data.\n",
            "\n",
            "**Applications of Machine Learning:**\n",
            "\n",
            "The video highlights a wide range of applications, demonstrating the versatility of machine learning:\n",
            "\n",
            "* **Speech Recognition:**  Powering virtual assistants like Siri and Google Assistant.\n",
            "* **Web Search:** Improving search engine results using algorithms like Naive Bayes.\n",
            "* **Recommendation Systems:** Suggesting products or content based on user preferences.\n",
            "* **Computer Vision:** Enabling computers to \"see\" and understand images and videos, identifying objects and scenes.\n",
            "* **Information Retrieval:**  Optimizing search results from vast amounts of data.\n",
            "* **Fraud Detection:** Identifying fraudulent activities online.\n",
            "\n",
            "**Types of Machine Learning:**\n",
            "\n",
            "The video categorizes machine learning into three main types:\n",
            "\n",
            "* **Supervised Learning:** The training data is labeled, meaning the desired outcome is known.  This allows the model to learn the relationship between input features and the output.  It's further divided into:\n",
            "    * **Classification:** Predicting categorical outcomes (e.g., spam/not spam).\n",
            "    * **Regression:** Predicting continuous outcomes (e.g., house price).\n",
            "* **Unsupervised Learning:** The training data is unlabeled, and the model aims to discover patterns and structures in the data. Examples include clustering and dimensionality reduction.\n",
            "* **Reinforcement Learning:**  An agent learns to interact with an environment by trial and error, receiving rewards or penalties based on its actions.  This is common in game playing and robotics.\n",
            "\n",
            "**Building a Machine Learning Model: The Process**\n",
            "\n",
            "The video outlines a typical workflow:\n",
            "\n",
            "1. **Data Preprocessing:** Cleaning, scaling, encoding, and selecting relevant features from the raw data.\n",
            "2. **Algorithm Selection:** Choosing the appropriate algorithm (e.g., decision tree, random forest, K-nearest neighbors) based on the problem type and data characteristics.\n",
            "3. **Model Building:** Applying the chosen algorithm to the preprocessed data to create a predictive model.\n",
            "4. **Model Evaluation:** Assessing the model's accuracy and performance using appropriate metrics.  The video emphasizes building multiple models and comparing their performance.\n",
            "\n",
            "**Key Terms:**\n",
            "\n",
            "The video introduces important terminology, such as features, attributes, samples, instances, observations, target variable, response variable, and the importance of understanding these terms within the context of a dataset.  The Iris dataset is mentioned as a commonly used example for practicing machine learning techniques.\n",
            "\n",
            "\n",
            "In summary, the video provides a foundational overview of machine learning, covering its definition, applications, types, and the general process of building and evaluating models.  It emphasizes the importance of hands-on practice and further exploration of various algorithms.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    \"\"\"Performs sentiment analysis on the YouTube video transcript.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Analyze the sentiment of this YouTube video transcript. Is it positive, negative, or neutral?\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "sentiment = analyze_sentiment(video_transcript)\n",
        "print(\"Sentiment Analysis:\\n\", sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "ATgrJO0iYEhk",
        "outputId": "cc504057-1a99-4e68-c679-4d8a1a9acd95"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis:\n",
            " The sentiment of the YouTube video transcript is overwhelmingly **positive**.  The speaker is enthusiastic and encouraging throughout.  While the content is technical (explaining machine learning concepts), the tone is optimistic and geared towards helping the viewer learn.  Phrases like \"very smarter applications,\"  \"growing a lot,\"  \"very good,\" and \"very intelligent application\" contribute to the positive sentiment. The speaker consistently uses positive language to describe machine learning and its potential applications. The overall aim is to inspire learners to engage with the topic.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Gh-pMgaYbKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}